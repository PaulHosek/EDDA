---
title: "wk1ex4"
author: "Robert Satzger"
date: "2/20/2023"
output: html_document
---

```{r, include=FALSE}
source("../utilities.R")
```


# Exercise 4. Yield of peas
**a)**
```{r, include = F}
library(MASS)
```

```{r}
random_plots <- cbind(
  rep(1:24),
  rep(1:6, each = 4),
  replicate(3, c(replicate(6, sample(c(1,1,0,0)))))
)
plots_df <- data.frame(random_plots)
header <- c("plot", "block", "N", "P", "K")
colnames(plots_df) <- header
plots_df[1:8,]
```

**b)**

The following plots show the average yield per block for plots treated with or without Nitrogen (N).

```{r, echo=FALSE}
attach(npk)
par(mfrow=c(1,2))
interaction.plot(block,N,yield)
interaction.plot(N,block,yield)
```
It is noteworthy that the study generally follows an incomplete block design. This would suggest interactions cannot be evaluated. However, taking only the factors block and N into account, there are two observations per condition. This means, the interactions may be evaluated.

Even though the yield is consistently higher for plots treated with Nitrogen, the size of this effect may differ between blocks. Taking this potential interaction of block and Nitrogen into account can help explain some of the variance in the treatment effect. Therefore, it can help improve the model fit. By performing a full two-way ANOVA, we can test whether the interaction is, in fact, present.

**c)**

To perform an ANOVA, we first check the normality assumption with the following plots.

```{r}
npk$block <- as.factor(npk$block)
npk$N <- as.factor(npk$N)
shapiro <- check_normality("yield", npk, c("block","N"))
```
The histogram and the QQ-plot indicate a normal distribution. Moreover, the Shapiro-Wilk test returns $p = `r sprintf('%.2f',shapiro[[1]]$p.value)`$. Therefore, we do not find a violation of the normality assumption.
Second, we check for homogeneity of variances.

```{r}
lm_aov1 = lm(yield ~ block * N, data = npk)
check_vars(lm_aov1)
```
The Q-Q plot of the residuals indicates a violation of the assumption of homogeneity of variances. Therefore, we drop the interaction term from the model.

```{r}
lm_aov12 = lm(yield ~ block + N, data = npk)
check_vars(lm_aov12)
```

With the removal of the interaction term, equal variances may be assumed. For completeness, we will proceed with both models.

```{r}
aov1 = anova(lm_aov1)
print("Anova without interaction term.")
print(aov1)
aov2 = anova(lm_aov12)
print("")
print("Anova with the interaction term.")
print(aov2)
```
The model without the interaction term and with the interaction term both draw a similar picture. There does not appear to be an interaction effect of block x Nitrogen on yield. Therefore, block does not affect our research question about the effect of Nitrogen on yield. A more sensible way to take block into account in the analysis would be in an additive model.

The Friedman test is not applicable in this case because there are two observations of the outcome variable (yield) per block x Nitrogen combination. In contrast, the Friedman test only applies to situations with 1 observation per factor combination.

**d)**
```{r}
# Define the models
models <- list(
  lm(yield ~ block * N + P + K, npk),
  lm(yield ~ block * N + K, npk),
  lm(yield ~ block * N + P, npk),
  lm(yield ~ block * N, npk),
  lm(yield ~ block + N, npk),
  
  lm(yield ~ block * P + K + N, npk),
  lm(yield ~ block * K + N + P, npk)
)

result_matrix <- matrix("-",nrow = 8, ncol = length(models), dimnames = list(c("Sum of Squares","block", "N", "P", "K","block:N","block:P","block:K"), paste0("model", 1:length(models))))

# loop through each model
for (i in 1:length(models)) {
  anova_table <- anova(models[[i]])
  terms_in_model <- attr(terms(models[[i]]), "term.labels")
  count_terms <- 1
  for (term in terms_in_model){
    
    result_matrix[term, i] <- ifelse(anova_table[count_terms, "Pr(>F)"] < 0.05, paste0(term, "*"), term)
    count_terms <- count_terms+1
  }
  result_matrix["Sum of Squares", i] <- round(anova(models[[i]])[nrow(anova(models[[i]])), "Sum Sq"],2)

}

result_matrix

```
Our result table compare different models. For each possible term in the model, we indicated whether the term is part of the model by writing the term in the cell (e.g., N) or not ("-"). Further, if the term was significant it is written with an asterisk (e.g., K*). As such, we can reconstruct how each model looks from this table. We also provide the Sum of Square of the model as an indicator of model fit. We can see that dropping P from the model between models 1 and 2 reduces model fit much less than dropping K (model3). Further, model 1 and 2 have the best fit. We also observer that if we drop the interaction term from the model (model5), model fit severely suffers. Based on our previous analysis and the current observations (and Occam's razor), we prefer model 2. Model 2 does not include P (potassium), so it is much more parsimonious. If predictions must be as precise as possible and measuring potassium is not a lot of work, model 1 should be preferred instead.


**e)**

Below, we base our normality assumption on the checks done in **c**.

```{r}
library(lme4)
mixed_model <- lmer(yield ~ N + (1|block), REML=FALSE, data = npk)
mixed_model1 <- lmer(yield ~ (1|block), REML=FALSE, data = npk)
anova(mixed_model1, mixed_model)
```
[COMPARE TO C]
