---
title: "w2ex3"
author: "Paul Hosek"
date: "`r Sys.Date()`"
output: pdf_document
---


```{r, include=FALSE}
source("../utilities.R")
library(ggplot2)
library(dplyr)
library(ggpubr)
library(car)
library(knitr)
```

- models will only work with !nan ages

#3
## a)
- multiple summaries of data
- fit log regression,, w/o interactions -> survival & predictor Pclass, age, sex
```{r, echo =TRUE}
data_titanic <- read.table("titanic.txt", header=TRUE)
data_titanic$PClass <- as.factor(data_titanic$PClass)
data_titanic$Sex <- as.factor(data_titanic$Sex)
data_titanic$Survived <- as.factor(data_titanic$Survived)
```


```{r, echo =FALSE}
ggplot(subset(data_titanic, Sex == "male"),
       aes(x = Age, fill = factor(Survived)))+
geom_histogram(binwidth = 5)+
scale_fill_discrete(labels = c("Not survived", "Survived"))+
  labs(title = "Survival by age: Males") + theme(aspect.ratio = .5)

ggplot(subset(data_titanic, Sex == "female"),
           aes(x = Age, fill = factor(Survived))) +
  geom_histogram(binwidth = 5)+scale_fill_discrete(labels = c("Not survived",
                                                              "Survived"))+
  labs(title = "Survival by age: Females") + theme(aspect.ratio = .5)

ggplot(data_titanic, aes(x = PClass, fill = factor(Survived))) +
  geom_bar()+scale_fill_discrete(labels = c("Not survived", "Survived"))+
labs(title = "Survival by class") + theme(aspect.ratio = .5)


```
```{r, echo =TRUE}
model_log1 <- glm(Survived ~ PClass + Age + Sex, data = data_titanic, family = binomial())
summary(model_log1)
```
Excluding interaction effects, we find that being a female or a first class passengers or young increases your odds of survival. However, we cannot know how a combination of these will impact the odds. From the main effects we can conclude: Males are $`r sprintf('%.2f',1/exp(coef(model_log1)["Sexmale"]))`$ more likely to die compared to females. 2nd-class passengers are $`r sprintf('%.2f',1/exp(coef(model_log1)["PClass2nd"]))`$ and third-class passengers are $`r sprintf('%.2f',1/exp(coef(model_log1)["PClass3rd"]))`$ as likely to die than passengers in other classes (calculated as 1/exp(coefficient_of_interest)). Further, for each year a person is older, odds decrease by a factor of $`r sprintf('%.2f',exp(coef(model_log1)["Age"]))`$: younger passengers are more likely to survive (calculated as exp(age)). All these main effects are statistically significantly associated with survival.

## b)
```{r, echo =TRUE}
model_log2 <- glm(Survived ~ PClass + Age + Sex + PClass:Age + Age:Sex, data = data_titanic, family = binomial)
summary(model_log2)
```

```{r, echo =TRUE}
all_comb_55 <- expand.grid(PClass = levels(data_titanic$PClass), Sex = levels(data_titanic$Sex), Age = 55)
all_comb_55$Survival_Probability <- predict(model_log2, all_comb_55, type = "response") # response = probabilities, "link" for odds
kable(all_comb_55, format = "latex", caption = "Survival probability for 55 year olds.")
```
We observe that being female has the largest influence on survival. Independent of gender, more expensive classes have larger survival probability. We observe that females in the first class have a extremely high survival probability of $`r sprintf('%.2f',all_comb_55$Survival_Probability[[1]])`$.

## c)

We can use the estimated logistic regression model to predict the probability of survival for a new observation, and then apply a threadshold to classify the observation as either a survivor (1) or a non-survivor (0).

Here, we first fit the logistic regression model to the observed data to estimate $\hat{\theta}$ in $P\left(Y_k=1\right)=\frac{1}{1+e^{-x_k^T \theta}}, \quad k=1, \ldots, N$. Then, we use this estimate to predict the probability of survival for a new passenger with predictor values $X_{new}$. We then apply a threshold  $p_0$ to classify the new passenger into survivor (1) or a non-survivor (0). Specifically, whether the predicted probability $\hat{P}_{new}$ is above or below the threshold is used to classify a new passenger.

The threshold $p_0$ determines the trade-off between sensitivity and specificity of our model. We may choose a validation set and some quality measure (e.g., accuracy: predictions correct) to maximize on this data set. Note, however, that this quality measure should be chosen depending on what our goal is, if we want high sensitivity or high specificicity, maximizing these may also guide the threshold.

## d)
```{r, echo =TRUE}
ct_class <- xtabs(~ PClass + Survived, data = data_titanic)
ct_class
xtest_class <- chisq.test(ct_class)
xtest_class
```

```{r, echo =TRUE}
ct_sex <- xtabs(~ Sex + Survived, data = data_titanic)
ct_sex
# chisq.test(ct_sex)
xtest_sex <- fisher.test(ct_sex)
xtest_sex
```
Here, we find that both class and sex have significant p-values. This indicates, that survival odds are not independent of neither sex nor class. The tables of residuals below show that the higher the class, relatively more people survive. The same is true for females compared to males.
```{r, echo =TRUE}
residuals(xtest_class)
residuals(chisq.test(ct_sex))
```
## e)
The approach in d) is not wrong, but has limited interpretability. Specifically, the contingency table is limited by its simplicity. It does not account for confounding variables (e.g., age in this case), leading to potentially false conclusions. This is related to the fact that no continuous predictors can be added to this model. Further, this approach does not provide us with a strength of the association between predictor and outcome. Logistic regression on the other hand, is able to account for multiple predictors simultaneously and estimate the magnitude and direction of predictor-outcome relationships. This may be further built upon to predict new data using a machine learning based on some quality criterion. However, logistic regression is more complex and less intuitive than a contingency table, so to guide hypothesis, it may be better to use a contingency table.